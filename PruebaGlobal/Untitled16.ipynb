{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import webbrowser\n",
    "from sklearn import neighbors\n",
    "import os\n",
    "from time import sleep\n",
    "import os.path\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "from face_recognition.face_recognition_cli import image_files_in_folder\n",
    "#import pygame\n",
    "from tempfile import TemporaryFile\n",
    "import time\n",
    "import cv2\n",
    "import threading\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "import shutil\n",
    "\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}\n",
    "#global video_capture \n",
    "#video_capture = cv2.VideoCapture(1)\n",
    "global frame, is_exit\n",
    "\n",
    "def show_webcam(mirror=False):\n",
    "            scale=10\n",
    "            cam = cv2.VideoCapture(0)\n",
    "            while True:\n",
    "                ret_val, img = cam.read()\n",
    "                if mirror: \n",
    "                    img = cv2.flip(img, 1)\n",
    "\n",
    "\n",
    "                #get the webcam size\n",
    "                height, width, channels = img.shape\n",
    "\n",
    "                #prepare the crop\n",
    "                centerX,centerY=int(height/2),int(width/2)\n",
    "                radiusX,radiusY= int(scale*height/100),int(scale*width/100)\n",
    "\n",
    "                minX,maxX=centerX-radiusX,centerX+radiusX\n",
    "                minY,maxY=centerY-radiusY,centerY+radiusY\n",
    "\n",
    "                cropped = img[minX:maxX, minY:maxY]\n",
    "                resized_cropped = cv2.resize(cropped, (width, height)) \n",
    "\n",
    "                cv2.imshow('my webcam', resized_cropped)\n",
    "                if cv2.waitKey(1) == 27: \n",
    "                    break  # esc to quit\n",
    "\n",
    "                #add + or - 5 % to zoom\n",
    "\n",
    "                if cv2.waitKey(1) == 0: \n",
    "                    scale += 5  # +5\n",
    "\n",
    "                if cv2.waitKey(1) == 1: \n",
    "                    scale = 5  # +5\n",
    "\n",
    "            cv2.destroyAllWindows()\n",
    "def voiceSpeech(nameText):\n",
    "    tts = gTTS('Buenos días, '+ nameText+'...','es-es')\n",
    "    tts.save('BD.mp3')\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(\"BD.mp3\")\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "def capture():\n",
    "    global frame,is_exit\n",
    "    while not is_exit:\n",
    "        # Grab a single frame of video\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # Recorre a través de cada persona en el conjunto de entrenamiento\n",
    "    for class_dir in os.listdir(train_dir):\n",
    "        \n",
    "        if not os.path.isdir(os.path.join(train_dir, class_dir)):\n",
    "            continue\n",
    "\n",
    "        # Recorre cada imagen de entrenamiento para la persona actual\n",
    "        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\n",
    "            image = face_recognition.load_image_file(img_path)\n",
    "            face_bounding_boxes = face_recognition.face_locations(image)\n",
    "                     \n",
    "            if len(face_bounding_boxes) != 1:\n",
    "                # Filtro de muchas caras\n",
    "                if verbose:\n",
    "                    print(\"Imagen {} no es recomendable para el entrenamiento: {}\".format(img_path, \"No se encontraron caras\" if len(face_bounding_boxes) < 1 else \"Muchas caras encontradas\"))\n",
    "            else:\n",
    "                # Codifica imagen actual del conjunto de entrenamiento\n",
    "                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\n",
    "                y.append(class_dir)\n",
    "    # Calcula numero de vecinos\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int(round(math.sqrt(len(X))))\n",
    "        if verbose:\n",
    "            print(\"Numero de vecinos encontrados:\", n_neighbors)\n",
    "\n",
    "    # Crea y entrena el KNN\n",
    "    \n",
    "    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')   \n",
    "    knn_clf.fit(X, y)\n",
    "\n",
    "\n",
    "    # Guarda el kernel generado\n",
    "    if model_save_path is not None:\n",
    "        with open(model_save_path, 'wb') as f:\n",
    "            pickle.dump(knn_clf, f)\n",
    "\n",
    "    return knn_clf\n",
    "\n",
    "def zoom(frame=None,mirror=False,cam=None,scale=None):\n",
    "    \n",
    "    #scale=10\n",
    "    #cam = cv2.VideoCapture(0)\n",
    "\n",
    "    ret_val, frame = cam.read()\n",
    "    if mirror: \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        #get the webcam size\n",
    "    height, width, channels = frame.shape\n",
    "        #prepare the crop\n",
    "    centerX,centerY=int(height/2),int(width/2)\n",
    "    radiusX,radiusY= int(scale*height/100),int(scale*width/100)\n",
    "\n",
    "    minX,maxX=centerX-radiusX,centerX+radiusX\n",
    "    minY,maxY=centerY-radiusY,centerY+radiusY\n",
    "\n",
    "    cropped = frame[minX:maxX, minY:maxY]\n",
    "    resized_cropped = cv2.resize(cropped, (width, height))\n",
    "    small_frame = cv2.resize(resized_cropped, (0, 0), fx=0.25, fy=0.25)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "    return rgb_small_frame\n",
    "\n",
    "def predict(X_img, knn_clf=None, model_path=None, distance_threshold=0.6):\n",
    "   \n",
    "    #Validacion de extension \n",
    "    #if not os.path.isfile(X_img_path) or os.path.splitext(X_img_path)[1][1:] not in ALLOWED_EXTENSIONS:\n",
    "       # raise Exception(\"Formato de imagen no admitido: {}\".format(X_img_path))\n",
    "\n",
    "    #validacion de ruta de clasificador ya entrenado\n",
    "    if knn_clf is None and model_path is None:\n",
    "        raise Exception(\"Debe proporcionar el archivo del clasificador o la ruta \")\n",
    "\n",
    "    # carga un modelo entrenado\n",
    "    if knn_clf is None:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            knn_clf = pickle.load(f)\n",
    "\n",
    "    # carga archivo de imagen \n",
    "    #X_img = face_recognition.load_image_file(X_img_path)\n",
    "    X_face_locations = face_recognition.face_locations(X_img)\n",
    "\n",
    "    # Devuelve cero si no hay caras\n",
    "    if len(X_face_locations) == 0:\n",
    "        return []\n",
    "\n",
    "    # Encontrar codificaciones para caras en el image.\n",
    "    faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_face_locations)\n",
    "\n",
    "    # Utilizamos el knn en nuestro conjunto definido para la cara de prueba\n",
    "    closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1)\n",
    "    #print(closest_distances)\n",
    "    are_matches = [closest_distances[0][i][0] <= distance_threshold for i in range(len(X_face_locations))]\n",
    "\n",
    "    # Predecir clases y eliminar clasificaciones que no están dentro del umbral\n",
    "    return [(pred, loc) if rec else (\"Desconocido\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_face_locations, are_matches)]\n",
    "\n",
    "def show_prediction_labels_on_image(img_path, predictions):\n",
    "   \n",
    "    pil_image = Image.open(img_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    for name, (top, right, bottom, left) in predictions:\n",
    "        # Dibuja un cuadro\n",
    "        draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
    "       \n",
    "        name = name.encode(\"UTF-8\")\n",
    "\n",
    "        # Dibuja una etiqueta con un nombre debajo de la cara\n",
    "        text_width, text_height = draw.textsize(name)\n",
    "        draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
    "        draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
    "    # Elimina la biblioteca de dibujos de memoria RAM\n",
    "    del draw\n",
    "    # Muestra la imagen resultante\n",
    "    pil_image.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    origin = \"ClasificadorKNN/train\"\n",
    "    dest = \"ClasificadorKNN/invitados/\"\n",
    "    #webbrowser.open('translate.google.com/translate_tts?ie=UTF-8&total=1&idx=0&textlen=32&client=tw-ob&q=Buenos+DIas+prueba&tl=es')\n",
    "    cam = cv2.VideoCapture(0)\n",
    "\n",
    "    Known_face_personalHitss=[]\n",
    "\n",
    "    Known_face_bandera=[]\n",
    "\n",
    "    face_locations = []\n",
    "    face_encodings = []\n",
    "    face_names = []\n",
    "    \n",
    "    process_this_frame = True\n",
    "\n",
    "    guessID = 1\n",
    "\n",
    "    files = os.listdir(origin)\n",
    "    for name in files:\n",
    "        print(name)\n",
    "        full_path = os.path.join(origin, name)\n",
    "        if os.path.isdir(full_path):\n",
    "            Known_face_personalHitss.append(name)\n",
    "            Known_face_bandera.append(0)\n",
    "    #print(\"Entrenando Clasificador KNN\")\n",
    "    #classifier = train(\"ClasificadorKNN/train\", model_save_path=\"trained_knn_model.clf\", n_neighbors=2)\n",
    "    #print(\"Entrenamiento Completo!\")\n",
    "    scale=10\n",
    "    while True:\n",
    "        \n",
    "        ret, frame = cam.read()\n",
    "        \n",
    "        rgb_small_frame=zoom(frame=frame,mirror=True,cam=cam,scale=10)\n",
    "\n",
    "        X_img = rgb_small_frame\n",
    "\n",
    "        if process_this_frame:\n",
    "\n",
    "            face_locations = face_recognition.face_locations(X_img)#,number_of_times_upsample=2)\n",
    "            face_encodings = face_recognition.face_encodings(X_img)\n",
    "            #print(\"Buscando caras en {}\".format(image_file))\n",
    "            #print(face_locations)\n",
    "            predictions = []\n",
    "            print(predictions)\n",
    "            #predictions = predict(X_img, model_path=\"trained_knn_model.clf\",distance_threshold=0.44)\n",
    "                \n",
    "            if face_locations:\n",
    "                predictions = predict(X_img, model_path=\"trained_knn_model.clf\",distance_threshold=0.44)\n",
    "                \n",
    "                print(predictions)\n",
    "                if predictions:\n",
    "                    faceID = Known_face_personalHitss.index(str(predictions[0][0])) if (predictions[0][0]!='Desconocido') else -1\n",
    "                    print(\"FACE ID: \",faceID)\n",
    "\n",
    "                    if faceID != -1:\n",
    "                        if Known_face_bandera[faceID] == 0:\n",
    "                            Known_face_bandera[faceID] = 1\n",
    "                                        \n",
    "                            print(Known_face_bandera[faceID])\n",
    "\n",
    "                            voiceSpeech(str(predictions[0][0]))\n",
    "                            \n",
    "                            print(\"CONTROL CONOCIDO\")\n",
    "                    else:\n",
    "                        Known_face_bandera.append(-1);\n",
    "                        Known_face_personalHitss.append('Invitado ' + str(guessID))\n",
    "                        \n",
    "                        #voiceSpeech('Por favor identifiquese con la recepcionista')\n",
    "                        #time.sleep(0.01)\n",
    "                        #cv2.imwrite(dest + \"invitado%d.jpg\" % guessID, frame) \n",
    "                        \n",
    "                        guessID = guessID + 1\n",
    "\n",
    "                        #full_file_path = os.path.join(imgFile)\n",
    "                        #print(\"RUTA: \", full_file_path)\n",
    "                        #src = full_file_path\n",
    "                        #shutil.move(src, dest)\n",
    "                        print(\"CONTROL DESCONOCIDO\")\n",
    "                #print(\"Buenos Dias \"+predictions[0][0])\n",
    "        process_this_frame= not process_this_frame\n",
    "\n",
    "            #else:\n",
    "                #predictions = predict(X_img, model_path=\"trained_knn_model.clf\",distance_threshold=0.44)\n",
    "                #print(predictions)\n",
    "                #print(\"AQUI NO HAY NADIE\")\n",
    "                #print(face_locations)\n",
    "            #print(full_file_path)\n",
    "            \n",
    "            #for name, (top, right, bottom, left) in predictions:\n",
    "                #print(\"- Encontrado  {} en ({}, {})\".format(name, left, top))\n",
    "\n",
    "            #show_prediction_labels_on_image(os.path.join(\"ClasificadorKNN/test\", X_img), predictions)\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        \n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "\n",
    "            cv2.rectangle(X_img, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "            \n",
    "            cv2.rectangle(X_img, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(X_img, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow('Video', X_img)\n",
    "    \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENTRENAMIENTO DE FACE RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import face_recognition \n",
    "import numpy as np\n",
    "import concurrent.futures\n",
    "\n",
    "concurrent.futures.ProcessPoolExecutor.map()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
