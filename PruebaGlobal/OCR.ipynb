{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACCION DE TEXTO OCR-OPENCV -CON FILTROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Redimensionamiento\n",
    "#binarizacion\n",
    "#reduccion de ruidos\n",
    "#rotacion/alineamiento\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#img=Image.open(\"test6.jpeg\")\n",
    "#texto = pytesseract.image_to_string(im)\n",
    "#print(texto)\n",
    "img=cv2.imread(\"ultimo.jpg\")\n",
    "img = cv2.resize(img, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_CUBIC)\n",
    "img= cv2.cvtColor (img, cv2.COLOR_BGR2GRAY)\n",
    "kernel = np.ones((1, 1), np.uint8)\n",
    "img = cv2.dilate(img, kernel, iterations=500)\n",
    "img = cv2.erode(img, kernel, iterations=500)\n",
    "# Apply blur to smooth out the edges\n",
    "img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "img = cv2.threshold (img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) [1]\n",
    "cv2.imwrite('ultimo2.jpg',img)\n",
    "texto=pytesseract.image_to_string(img,lang='spa')\n",
    "#texto=pytesseract.image_to_string(img)\n",
    "#cv2.imshow(\"imagen\",img)\n",
    "print(texto)\n",
    "#print(\"HOLA MUNDO\")\n",
    "#print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR CON LIBRERIA PYOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyocr\n",
    "import pyocr.builders\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from wand.image import Image as Img\n",
    "from PIL import Image\n",
    "\n",
    "#with Img(filename='test5.jpg', resolution=300) as img:\n",
    "    #img.compression_quality = 99\n",
    "    #img.save(filename='ultimo2.jpg')\n",
    "    \n",
    "img = Image.open('test5.jpg')\n",
    "print(type(img))\n",
    "crop_img = img.crop((250,40,410, 250))\n",
    "crop_img.save('ultimo2.jpg')\n",
    "#image=cv2.imread(\"test2.jpg\")\n",
    "img = Image.open ('ultimo2.jpg') \n",
    "#img = img.convert ('L') \n",
    "img.save ('ultimo2.jpg')\n",
    "tools = pyocr.get_available_tools()[0]\n",
    "text = tools.image_to_string(Image.open('ultimo2.jpg'),builder=pyocr.builders.DigitBuilder())\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR LIBRERIA PYOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer Apetlido\n",
      "VALENZUELA\n",
      "\n",
      "Segundo Apellido\n",
      "soto\n",
      "\n",
      "Pre Nombres\n",
      "JOSE MANUEL\n",
      "\n",
      "Nacimiento: Fechs\n",
      "2602 1901 â€™\n"
     ]
    }
   ],
   "source": [
    "import pyocr\n",
    "import pyocr.builders\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from wand.image import Image as Img\n",
    "from PIL import Image\n",
    "#import face_recognition\n",
    "\n",
    "def deteccion_texto(img=None):\n",
    "   \n",
    "    crop_img = img.crop((250,40,410, 250))#datos\n",
    "    #cro_img=img.crop((50,50,50,150))\n",
    "    #crop_img.save('apellido.jpg')\n",
    "    #image=cv2.imread(\"test2.jpg\")\n",
    "    #img = Image.open ('apellido.jpg') \n",
    "    crop_img = crop_img.convert ('L')\n",
    "    #img.save ('apellido.jpg')\n",
    "    tools = pyocr.get_available_tools()[0]\n",
    "    text = tools.image_to_string(crop_img,builder=pyocr.builders.DigitBuilder())\n",
    "    print(text)\n",
    "#def face_crow(img=None):\n",
    "    #img2=face_recognition.load_image_file(img)\n",
    "    #locations=face_recognition.face_locations(img2)\n",
    "   # print(locations)\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    img=Image.open('test5.jpg')\n",
    "    deteccion_texto(img)\n",
    "    #image=face_recognition.load_image_file(\"test5.jpg\")\n",
    "    #locations=face_recognition.face_locations(image)\n",
    "    #print(locations)\n",
    "    #for face_location in locations:\n",
    "    #X1,Y2,X2,Y1=face_location\n",
    "    #print(X1,Y1,X2,Y2)\n",
    "    #image=Image.open('test5.jpg')\n",
    "    #crop_img=image.crop((96, 110, 225,239))\n",
    "    #crop_img.save('cara.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACCION DE TEXTO OCR-IMAGEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redimensionamiento\n",
    "#binarizacion\n",
    "#reduccion de ruidos\n",
    "#rotacion/alineamiento\n",
    "from PIL import Image \n",
    "import pytesseract\n",
    "import cv2\n",
    "\n",
    "#im=Image.open(\"test.jpeg\")\n",
    "#texto = pytesseract.image_to_string(im)\n",
    "#print(texto)\n",
    "im=Image.(\"test2.jpg\")\n",
    "texto=pytesseract.image_to_string(im)\n",
    "print(texto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESCALA DE GRISES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load an color image in grayscale\n",
    "img = cv2.imread('test.jpeg',0)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECONOCIMIENTO DE ROSTRO EN DNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "\n",
    "img=cv2.imread(\"test.jpeg\")\n",
    "face_location=face_recognition.face_locations(img)\n",
    "print(face_location)\n",
    "print(\"HOLA MUNDO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRERIA PYOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyocr\n",
    "import pyocr.builders\n",
    "from PIL import Image\n",
    "\n",
    "tools = pyocr.get_available_tools()[0]\n",
    "img = Image.open('test.jpeg')\n",
    "img = img.convert('L')\n",
    "img.save('test.jpeg')\n",
    "img=Image.open('test.jpeg')\n",
    "text = tools.image_to_string(img,builder=pyocr.builders.DigitBuilder())\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SERVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from flask import Flask, jsonify, request, redirect\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "# You can change this to any folder on your system\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and \\\n",
    "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def upload_image():\n",
    "    # Check if a valid image file was uploaded\n",
    "    if request.method == 'POST':\n",
    "        if 'file' not in request.files:\n",
    "            return redirect(request.url)\n",
    "\n",
    "        file = request.files['file']\n",
    "\n",
    "        if file.filename == '':\n",
    "            return redirect(request.url)\n",
    "\n",
    "        if file and allowed_file(file.filename):\n",
    "            # The image file seems valid! Detect faces and return the result.\n",
    "            return detect_faces_in_image(file)\n",
    "\n",
    "    # If no valid image file was uploaded, show the file upload form:\n",
    "    return '''\n",
    "    <!doctype html>\n",
    "    <title>Is this a picture of Obama?</title>\n",
    "    <h1>OCR-GlobalHitss-Prueba</h1>\n",
    "    <form method=\"POST\" enctype=\"multipart/form-data\">\n",
    "      <input type=\"file\" name=\"file\">\n",
    "      <input type=\"submit\" value=\"Upload\">\n",
    "    </form>\n",
    "    '''\n",
    "\n",
    "def pruebaOCR(img=None):\n",
    "    # Return the result as json\n",
    "    result = {\n",
    "        \"face_found_in_image\": face_found,\n",
    "        \"is_picture_of_obama\": is_obama\n",
    "    }\n",
    "    return jsonify(result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BINARIZACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract as ocr\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# tipando a leitura para os canais de ordem RGB\n",
    "imagem = Image.open('test.jpeg').convert('RGB')\n",
    "img=cv2.imread('test.jpeg')\n",
    "\n",
    "# convertendo em um array editÃ¡vel de numpy[x, y, CANALS]\n",
    "npimagem = np.asarray(imagem).astype(np.uint8)  \n",
    "\n",
    "# diminuiÃ§Ã£o dos ruidos antes da binarizaÃ§Ã£o\n",
    "npimagem[:, :, 0] = 0 # zerando o canal R (RED)\n",
    "npimagem[:, :, 2] = 0 # zerando o canal B (BLUE)\n",
    "\n",
    "# atribuiÃ§Ã£o em escala de cinza\n",
    "im = cv2.cvtColor(npimagem, cv2.COLOR_RGB2GRAY) \n",
    "#cv2.imshow(im)\n",
    "# aplicaÃ§Ã£o da truncagem binÃ¡ria para a intensidade\n",
    "# pixels de intensidade de cor abaixo de 127 serÃ£o convertidos para 0 (PRETO)\n",
    "# pixels de intensidade de cor acima de 127 serÃ£o convertidos para 255 (BRANCO)\n",
    "# A atrubiÃ§Ã£o do THRESH_OTSU incrementa uma anÃ¡lise inteligente dos nivels de truncagem\n",
    "ret, thresh = cv2.threshold(im, 127, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) \n",
    "\n",
    "# reconvertendo o retorno do threshold em um objeto do tipo PIL.Image\n",
    "binimagem = Image.fromarray(thresh) \n",
    "\n",
    "# chamada ao tesseract OCR por meio de seu wrapper\n",
    "phrase = ocr.image_to_string(binimagem,lang='spa')\n",
    "#cv2.imshow(im)\n",
    "print(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESCALAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract as ocr\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"test.jpeg\")\n",
    "img = cv2.resize (img, None, fx = 1.5, fy = 1.5, interpolaciÃ³n = cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
